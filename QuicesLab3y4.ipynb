{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosMejia07/Quices-Lab/blob/main/QuicesLab3y4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nueva sección"
      ],
      "metadata": {
        "id": "1Sy-hDQ7mvYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.1 Manually use a predictive model"
      ],
      "metadata": {
        "id": "UjCwvjE5nS4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_moons\n",
        "from local.lib import mlutils\n",
        "from IPython.display import Image\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kmOSJQYZmy5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = pd.read_csv(\"local/data/trilotropicos_small.csv\")\n",
        "X,y = d.values[:,:2], d.values[:,-1]\n",
        "print (d.shape, X.shape, y.shape)\n",
        "print (X[:5])\n",
        "print (y[:5])\n",
        "d.head()"
      ],
      "metadata": {
        "id": "-MDxz8rrm_2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X[y==0][:,0], X[y==0][:,1], color=\"blue\", label=\"X bug\")\n",
        "plt.scatter(X[y==1][:,0], X[y==1][:,1], color=\"red\", label=\"Z bug\")\n",
        "plt.xlabel(\"width\");plt.ylabel(\"length\"); plt.legend(); plt.grid();"
      ],
      "metadata": {
        "id": "5HRTT1RRnGUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, t):\n",
        "    return (~((X[:,0] < t[0]) & (X[:,1] > t[1]))).astype(int)"
      ],
      "metadata": {
        "id": "OE63Tag8nX4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = np.r_[.5,.3]\n",
        "y_hat = predict(X, t)\n",
        "y_hat\n",
        "np.mean(y==y_hat)\n",
        "mlutils.plot_2Ddata_with_boundary(lambda X: predict(X,t), X, y); plt.grid();\n",
        "t = np.r_[.5,.8]\n",
        "mlutils.plot_2Ddata_with_boundary(lambda X: predict(X,t), X, y); plt.grid();\n",
        "np.mean(y==predict(X,t))\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "mlutils.plot_2Ddata_with_boundary(LogisticRegression().fit(X,y).predict, X, y); plt.grid();\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "mlutils.plot_2Ddata_with_boundary(DecisionTreeClassifier(max_depth=5).fit(X,y).predict, X, y); plt.grid();\n",
        "from sklearn.svm import SVC\n",
        "mlutils.plot_2Ddata_with_boundary(SVC(gamma=50).fit(X,y).predict, X, y); plt.grid();"
      ],
      "metadata": {
        "id": "pOm-ph_5ntDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.2 Fit the model"
      ],
      "metadata": {
        "id": "n2tEo9QKnc7j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def fit(X,y):\n",
        "    def predict(X, t):\n",
        "        return (~((X[:,0] < t[0]) & (X[:,1] > t[1]))).astype(int)\n",
        "    grid = np.linspace(0, 1, 11)\n",
        "    best_acc = -1\n",
        "    best_t = None\n",
        "    for t0, t1 in itertools.product(grid, grid):\n",
        "        t = np.array([t0, t1])\n",
        "        y_pred = predict(X, t)\n",
        "        acc = (y_pred == y).mean()\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_t = t\n",
        "\n",
        "    return best_t"
      ],
      "metadata": {
        "id": "p86KvT1_ne4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = fit(X,y)\n",
        "mlutils.plot_2Ddata_with_boundary(lambda X: predict(X,t), X, y); plt.grid();\n",
        "np.mean(y==predict(X,t))\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "bX, by = make_blobs(100,n_features=2, centers=2)\n",
        "bX = MinMaxScaler(feature_range=(0.1,.9)).fit_transform(bX)\n",
        "bt = fit(bX, by)\n",
        "mlutils.plot_2Ddata_with_boundary(lambda X: predict(X,bt), bX, by); plt.grid();\n",
        "np.mean(by==predict(bX,bt))"
      ],
      "metadata": {
        "id": "Ri8Yu4iGpA_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.3 Make an sklearn compatible class with your model"
      ],
      "metadata": {
        "id": "UY3FIDoIpTWb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SimpleModel():\n",
        "    class _SimpleModel:\n",
        "\n",
        "        def __init__(self):\n",
        "            self.t = None  # aquí guardaremos [θ0, θ1]\n",
        "\n",
        "        def fit(self, X, y):\n",
        "            grid = np.linspace(0, 1, 11)\n",
        "            best_acc = -1\n",
        "\n",
        "            for t0, t1 in itertools.product(grid, grid):\n",
        "                t = np.array([t0, t1])\n",
        "                y_pred = self._predict_with_t(X, t)\n",
        "                acc = (y_pred == y).mean()\n",
        "                if acc > best_acc:\n",
        "                    best_acc = acc\n",
        "                    self.t = t  # guardamos los mejores parámetros\n",
        "\n",
        "            return self\n",
        "\n",
        "        def predict(self, X):\n",
        "            return self._predict_with_t(X, self.t)\n",
        "\n",
        "        # función auxiliar privada (usa t explícito)\n",
        "        def _predict_with_t(self, X, t):\n",
        "            return (~((X[:,0] < t[0]) & (X[:,1] > t[1]))).astype(int)\n",
        "\n",
        "\n",
        "    return _SimpleModel()"
      ],
      "metadata": {
        "id": "qOMk2ZJipX5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = SimpleModel()\n",
        "m.fit(X,y)\n",
        "m.predict(X)\n",
        "mlutils.plot_2Ddata_with_boundary(m.predict, X, y); plt.grid();\n",
        "np.mean(y==m.predict(X))\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "mX, my = make_moons(100, noise=.1)\n",
        "m = SimpleModel()\n",
        "m.fit(mX,my)\n",
        "\n",
        "mlutils.plot_2Ddata_with_boundary(m.predict, mX, my); plt.grid();\n",
        "np.mean(my==m.predict(mX))"
      ],
      "metadata": {
        "id": "Cy8sM7xDp7pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.21 Timeseries model - Build a time series training dataset"
      ],
      "metadata": {
        "id": "1Z14DgPUqUA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from local.lib import timeseries as ts\n",
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import Image\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kTGMdj-oqhcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "date_split = \"2018-03-01\"\n",
        "\n",
        "idx = pd.date_range(\"2018-01-01\", \"2018-03-31\", freq=\"6h\")\n",
        "i = np.linspace(-5,4,len(idx))\n",
        "i = np.linspace(np.random.random()*5-5,np.random.random()*5+2,len(idx))\n",
        "t = np.log(i**2+.3)*np.cos(4*i)\n",
        "t += (np.random.normal(size=len(idx))*.4)\n",
        "t = np.round(t*3+30,3)\n",
        "d = pd.DataFrame(np.r_[[t]].T, columns=[\"signal\"], index=idx)\n",
        "d.index.name=\"date\"\n",
        "\n",
        "plt.figure(figsize=(15,3))\n",
        "plt.plot(d[:date_split].index, d[:date_split].signal, color=\"black\", lw=\"2\", label=\"train\");\n",
        "plt.plot(d[date_split:].index, d[date_split:].signal, color=\"red\", lw=\"2\", label=\"test\");\n",
        "plt.axvline(date_split, color=\"grey\"); plt.legend();plt.grid();\n",
        "signal = d"
      ],
      "metadata": {
        "id": "Se918Xf3q200"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_timeseries_dataset(signal, n_timesteps_lookback):\n",
        "    import pandas as pd\n",
        "    r = signal.copy()\n",
        "    for i in range(1, n_timesteps_lookback + 1):\n",
        "        r[f\"signal-{i}\"] = r[\"signal\"].shift(i)\n",
        "    r[\"signal+1\"] = r[\"signal\"].shift(-1)\n",
        "    r = r.dropna()\n",
        "    return r"
      ],
      "metadata": {
        "id": "sQ6cY4gjrA6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_timeseries_dataset(d, n_timesteps_lookback=3).head(10)\n"
      ],
      "metadata": {
        "id": "opywtEWPrIVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.22 Manually apply a regression model to create predictions"
      ],
      "metadata": {
        "id": "bx4hsQicrM0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_linear_regression_model(td, w):\n",
        "    r = w[0] + td[[\"signal\"] + sorted([c for c in td.columns if c.startswith(\"signal-\")], key=lambda x: int(x.split(\"-\")[1]))].values @ w[1:]\n",
        "    return r"
      ],
      "metadata": {
        "id": "Dgulp_xYrSz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "td = make_timeseries_dataset(d, n_timesteps_lookback=np.random.randint(3)+2)\n",
        "td = td[np.random.permutation(td.columns)]\n",
        "td.head()\n",
        "w = np.random.random(len(td.columns))\n",
        "w\n",
        "apply_linear_regression_model(td[np.random.permutation(td.columns)], w)[:5]"
      ],
      "metadata": {
        "id": "o9wF94LKrh4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 3.23 Measure trend prediction"
      ],
      "metadata": {
        "id": "ZKtMdJFAroUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def measure_trend_accuracy(td, preds):\n",
        "    r = (( (td[\"signal+1\"] > td[\"signal\"]) & (preds > td[\"signal\"]) ) |\n",
        "            ( (td[\"signal+1\"] <= td[\"signal\"]) & (preds <= td[\"signal\"]) ) ).mean()\n",
        "    return r"
      ],
      "metadata": {
        "id": "6EclCm4srsRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "td = make_timeseries_dataset(d, n_timesteps_lookback=np.random.randint(3)+2).iloc[:10]\n",
        "td\n",
        "preds = td['signal'] + np.round(np.random.random()*4-2,3)\n",
        "preds\n",
        "measure_trend_accuracy(td, preds)"
      ],
      "metadata": {
        "id": "yBpyUMSPr1yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.1 Cleaning Data - FillNA in risk with corresponding city average"
      ],
      "metadata": {
        "id": "lATv_MPYsB16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from IPython.display import Image\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "Av43chYisPxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 20\n",
        "place = np.r_[[\"Medellin\", \"Bogota\", \"Madrid\"]][(np.random.randint(3, size=n))]\n",
        "age = np.random.randint(50, size=n)+10\n",
        "children = np.r_[[(np.random.randint(2) if i<30 else (np.random.randint(4))) for i in age]]\n",
        "risk = np.r_[[np.random.random()*(.2 if i==\"Medellin\" else .8) for i in place]].round(3)\n",
        "risk[np.random.permutation(len(risk))[:5]]=np.nan\n",
        "d01 = pd.DataFrame([age, risk, children, place], index=[\"age\", \"risk\", \"children\", \"place\"]).T\n",
        "d01.to_csv(\"risk.csv\", index=False)\n",
        "d01\n",
        "#k = d01[d01.place==\"Bogota\"][\"risk\"].dropna()\n",
        "#plt.scatter(k, [0]*len(k), label=\"Bogota\")\n",
        "#k = d01[d01.place==\"Medellin\"][\"risk\"].dropna()\n",
        "#plt.scatter(k, [1]*len(k), label=\"Medellin\")\n",
        "#k = d01[d01.place==\"Madrid\"][\"risk\"].dropna()\n",
        "#plt.scatter(k, [2]*len(k), label=\"Madrid\")\n",
        "#plt.grid();\n",
        "#plt.xlabel(\"risk level\")\n",
        "#plt.ylabel(\"city\")\n",
        "#plt.legend()\n"
      ],
      "metadata": {
        "id": "YRUDQtNrsUD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear DataFrame\n",
        "r01 = pd.DataFrame({\"place\": place, \"age\": age, \"children\": children, \"risk\": risk})\n",
        "\n",
        "# Calcular media por ciudad y reemplazar los NaN\n",
        "r01[\"risk\"] = r01[\"risk\"].fillna(r01.groupby(\"place\")[\"risk\"].transform(\"mean\"))\n",
        "\n",
        "r01.head()"
      ],
      "metadata": {
        "id": "i2NKVTlmsnfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.2 Standardize age so that min=0, max=1\n",
        "\n",
        "si=(xi−min)/(max−min)"
      ],
      "metadata": {
        "id": "_Z8Kv0MZubYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r02 = r01.copy()\n",
        "r02[\"age\"] = (r02[\"age\"] - r02[\"age\"].min()) / (r02[\"age\"].max() - r02[\"age\"].min())"
      ],
      "metadata": {
        "id": "a9mJccoauhsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.3 Standardize age so that  μ=0  and  σ=1\n",
        "\n",
        "si=(si−μ)/σ"
      ],
      "metadata": {
        "id": "Fm60gSMGvOYI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r03 = r01.copy()\n",
        "r03[\"age\"] = (r03[\"age\"] - r03[\"age\"].mean()) / r03[\"age\"].std()"
      ],
      "metadata": {
        "id": "JU7say7lvZF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.4 Create a one-hot encoding for place"
      ],
      "metadata": {
        "id": "lVAxSbRu1WDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "r04 = pd.get_dummies(r03, columns=[\"place\"])"
      ],
      "metadata": {
        "id": "j8BTu4vR1aRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.21 Buiding Datasets"
      ],
      "metadata": {
        "id": "iyAcECD52CKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "# from local.lib import labutils # Removing this as local files are not accessible\n",
        "import numpy as np\n",
        "# bid, date = labutils.biddate_for_student(student.user_id) # Removing this as labutils is not available\n",
        "# print (\"your building_id\", bid)\n",
        "# print (\"your date       \", date)"
      ],
      "metadata": {
        "id": "dVl2N89Q2MjV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '.'\n",
        "!chmod 600 ./kaggle.json\n",
        "!kaggle competitions download -c ashrae-energy-prediction\n",
        "!unzip ashrae-energy-prediction.zip > /dev/null\n",
        "!wc *.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtTKFX5v2TjW",
        "outputId": "b911ba85-a1e3-43f3-a9df-047d2fc33ba6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ashrae-energy-prediction.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "      1450       2177      45527 building_metadata.csv\n",
            "  41697601   41697601  447562511 sample_submission.csv\n",
            "  41697601   83395201 1462461085 test.csv\n",
            "  20216101   40432201  678616640 train.csv\n",
            "    277244     554487   14787908 weather_test.csv\n",
            "    139774     279547    7450075 weather_train.csv\n",
            " 104029771  166361214 2610923746 total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- 1. Cargar los archivos ---\n",
        "train = pd.read_csv(\"train.csv\", parse_dates=[\"timestamp\"])\n",
        "buildings = pd.read_csv(\"building_metadata.csv\")\n",
        "weather = pd.read_csv(\"weather_train.csv\", parse_dates=[\"timestamp\"])\n",
        "\n",
        "# --- 2. Filtrar el edificio y el día ---\n",
        "b_id = 921\n",
        "date = \"2016-02-14\"\n",
        "\n",
        "# Filtramos solo el edificio y día, y solo meter=0\n",
        "df = train[\n",
        "    (train[\"building_id\"] == b_id) &\n",
        "    (train[\"meter\"] == 0) &\n",
        "    (train[\"timestamp\"].dt.date == pd.to_datetime(date).date())\n",
        "].copy()\n",
        "\n",
        "# --- 3. Agregar metadata y clima ---\n",
        "# Añadir info del edificio\n",
        "df = df.merge(buildings, on=\"building_id\", how=\"left\")\n",
        "\n",
        "# Añadir clima (por site_id y timestamp)\n",
        "df = df.merge(weather, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
        "\n",
        "# --- 4. Seleccionar solo las columnas solicitadas ---\n",
        "cols = [\n",
        "    \"meter_reading\", \"site_id\", \"air_temperature\", \"cloud_coverage\",\n",
        "    \"dew_temperature\", \"precip_depth_1_hr\", \"sea_level_pressure\",\n",
        "    \"wind_direction\", \"wind_speed\", \"square_feet\", \"year_built\"\n",
        "]\n",
        "df = df[cols]\n",
        "\n",
        "# --- 5. Rellenar valores faltantes con 0 ---\n",
        "df = df.fillna(0)\n",
        "\n",
        "# --- 6. Calcular las sumas ---\n",
        "target_sum = int(df[\"meter_reading\"].sum())\n",
        "features_sum = int(df.drop(columns=[\"meter_reading\"]).sum().sum())\n",
        "\n",
        "print(f\"Target sum (meter_reading): {target_sum}\")\n",
        "print(f\"Features sum: {features_sum}\")\n",
        "print(f\"Total rows: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyqeK4EG4fg2",
        "outputId": "bffcfcbe-a59b-433a-b2d5-a6e487888ea4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target sum (meter_reading): 10087\n",
            "Features sum: 6319125\n",
            "Total rows: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.22 Time series missing data fix"
      ],
      "metadata": {
        "id": "O8rGgbmV4xp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from local.lib import labutils\n",
        "_, date = labutils.biddate_for_student(student.user_id)\n",
        "print (\"your date       \", date)"
      ],
      "metadata": {
        "id": "2ybeU9vs5Qqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar datos meteorológicos\n",
        "weather = pd.read_csv(\"weather_train.csv\", parse_dates=[\"timestamp\"])\n",
        "\n",
        "# Filtrar por site_id y fecha\n",
        "site_id = 3\n",
        "date = \"2016-02-14\"\n",
        "\n",
        "df = weather[\n",
        "    (weather[\"site_id\"] == site_id) &\n",
        "    (weather[\"timestamp\"].dt.date == pd.to_datetime(date).date())\n",
        "].copy()\n",
        "\n",
        "# Ordenar por hora para asegurar el orden temporal\n",
        "df = df.sort_values(\"timestamp\")\n",
        "\n",
        "# Extraer la columna de interés\n",
        "ts = df[\"cloud_coverage\"]\n",
        "\n",
        "# Rellenar valores NaN repitiendo el último valor conocido\n",
        "fixed_ts = ts.ffill().tolist()\n",
        "\n",
        "# Si los primeros valores son NaN y no hay previo, se pueden rellenar con 0 o el primer valor no nulo:\n",
        "if pd.isna(fixed_ts[0]):\n",
        "    first_valid = next((x for x in fixed_ts if pd.notna(x)), 0)\n",
        "    fixed_ts = [first_valid if pd.isna(x) else x for x in fixed_ts]\n",
        "\n",
        "print(fixed_ts)\n",
        "print(f\"Longitud: {len(fixed_ts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcCEscyS42AV",
        "outputId": "26aadfa9-e9db-418d-9638-a6c9da274ead"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 6.0, 6.0, 6.0]\n",
            "Longitud: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab 4.23 Build a time series predictive dataset"
      ],
      "metadata": {
        "id": "H33lX85S5UhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "ts = np.array(fixed_ts)\n",
        "n = 3  # número de valores previos usados para predecir el siguiente\n",
        "\n",
        "# Construir las ventanas (inputs)\n",
        "X = np.array([ts[i:i+n] for i in range(len(ts)-n)])\n",
        "# Construir los valores esperados (outputs)\n",
        "y = np.array([ts[i+n] for i in range(len(ts)-n)])\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n",
        "print(\"\\nEjemplo X[0]:\", X[0])\n",
        "print(\"Ejemplo y[0]:\", y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61uqnHXy5bXm",
        "outputId": "c835c044-ec17-40cf-98b2-200caaad5a25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (21, 3)\n",
            "y shape: (21,)\n",
            "\n",
            "Ejemplo X[0]: [0. 2. 2.]\n",
            "Ejemplo y[0]: 2.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}